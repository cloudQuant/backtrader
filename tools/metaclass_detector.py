#!/usr/bin/env python3
"""
Backtrader Metaclass Detection Tool

Day 8-10: å…ƒç¼–ç¨‹æ£€æµ‹å·¥å…·
- æ£€æµ‹é¡¹ç›®ä¸­çš„å…ƒç±»ä½¿ç”¨
- åˆ†æåŠ¨æ€ç±»åˆ›å»ºæ¨¡å¼
- ç”Ÿæˆè¯¦ç»†çš„è¿ç§»æŠ¥å‘Š
"""

import os
import sys
import ast
import json
import re
import importlib
import inspect
from typing import Dict, List, Set, Any, Tuple, Optional, Union
from datetime import datetime
from dataclasses import dataclass, field
from collections import defaultdict
import traceback

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


@dataclass
class MetaclassUsage:
    """å…ƒç±»ä½¿ç”¨è®°å½•"""
    class_name: str
    file_path: str
    line_number: int
    metaclass_name: str
    usage_type: str  # 'explicit', 'inheritance', 'dynamic'
    complexity_level: str  # 'simple', 'medium', 'complex'
    dependent_classes: List[str] = field(default_factory=list)
    migration_strategy: str = ''
    migration_priority: int = 3  # 1-5, 1æœ€é«˜


@dataclass
class DynamicCreation:
    """åŠ¨æ€ç±»åˆ›å»ºè®°å½•"""
    creation_id: str
    file_path: str
    line_number: int
    creation_type: str  # 'type_call', 'metaclass_direct', 'factory_pattern'
    target_class: str
    creation_code: str
    complexity_score: float
    migration_difficulty: str  # 'easy', 'medium', 'hard', 'complex'


@dataclass
class MigrationPlan:
    """è¿ç§»è®¡åˆ’"""
    target_class: str
    current_pattern: str
    target_pattern: str
    migration_steps: List[str]
    estimated_effort: int  # hours
    prerequisites: List[str] = field(default_factory=list)
    test_requirements: List[str] = field(default_factory=list)
    risk_factors: List[str] = field(default_factory=list)


class MetaclassDetector(ast.NodeVisitor):
    """å…ƒç±»æ£€æµ‹å™¨"""
    
    def __init__(self, file_path: str):
        self.file_path = file_path
        self.metaclass_usages: List[MetaclassUsage] = []
        self.dynamic_creations: List[DynamicCreation] = []
        self.imports: Dict[str, str] = {}
        self.class_definitions: Dict[str, ast.ClassDef] = {}
        
        # å·²çŸ¥çš„å…ƒç±»
        self.known_metaclasses = {
            'MetaBase', 'MetaParams', 'MetaLineSeries', 'MetaSingleton',
            'MetaIndicator', 'MetaStrategy', 'MetaAnalyzer', 'MetaObserver',
            'MetaBroker', 'MetaLineRoot', 'MetaLineIterator', 'MetaLineActions',
            'MetaAbstractDataBase', 'MetaCSVDataBase', 'MetaFilter',
            'MetaMovAvBase', 'MetaDataTrades', 'MetaTimeFrameAnalyzerBase',
            'MetaSigStrategy', 'MetaIBBroker', 'MetaCTPBroker', 'MetaVCBroker',
            'MetaOandaBroker', 'MetaCCXTBroker', 'MetaCryptoBroker',
            'MetaCCXTFeed', 'MetaCryptoFeed', 'MetaCTPData', 'MetaOandaData',
            'MetaRollOver', 'MetaIBData', 'MetaVCData', 'MetaVChartFile',
            'MetaChainer'
        }
        
        # åŠ¨æ€åˆ›å»ºæ¨¡å¼
        self.dynamic_patterns = [
            r'type\s*\(',  # type() calls
            r'__class__\s*=',  # class assignment
            r'setattr\s*\(\s*\w+\s*,\s*[\'"]__class__[\'"]',  # setattr __class__
            r'metaclass\s*=\s*\w+',  # metaclass assignment
            r'with_metaclass\s*\(',  # six.with_metaclass
        ]
    
    def visit_Import(self, node: ast.Import):
        """å¤„ç†importè¯­å¥"""
        for alias in node.names:
            name = alias.name
            as_name = alias.asname or name.split('.')[-1]
            self.imports[as_name] = name
        self.generic_visit(node)
    
    def visit_ImportFrom(self, node: ast.ImportFrom):
        """å¤„ç†from importè¯­å¥"""
        module = node.module or ''
        for alias in node.names:
            name = alias.name
            as_name = alias.asname or name
            full_name = f"{module}.{name}" if module else name
            self.imports[as_name] = full_name
        self.generic_visit(node)
    
    def visit_ClassDef(self, node: ast.ClassDef):
        """è®¿é—®ç±»å®šä¹‰"""
        self.class_definitions[node.name] = node
        
        # æ£€æŸ¥Python 3.xé£æ ¼çš„æ˜¾å¼å…ƒç±»ä½¿ç”¨ (class Foo(metaclass=Meta):)
        for keyword in getattr(node, 'keywords', []):
            if keyword.arg == 'metaclass':
                metaclass_name = self._get_name(keyword.value)
                if metaclass_name and metaclass_name in self.known_metaclasses:
                    self._record_metaclass_usage(
                        node.name, metaclass_name, node.lineno, 'explicit'
                    )
        
        # æ£€æŸ¥é€šè¿‡ç»§æ‰¿è·å¾—çš„å…ƒç±»
        for base in node.bases:
            base_name = self._get_name(base)
            if base_name and base_name in self.known_metaclasses:
                self._record_metaclass_usage(
                    node.name, base_name, node.lineno, 'inheritance'
                )
            
            # æ£€æŸ¥å·²çŸ¥ä½¿ç”¨å…ƒç±»çš„åŸºç±»
            known_metaclass_users = {
                'ParamsBase', 'LineSeries', 'LineMultiple', 'Strategy', 
                'Indicator', 'Observer', 'Analyzer', 'Store', 'BrokerBase',
                'DataBase', 'Timer', 'Sizer', 'Filter', 'LineIterator'
            }
            if base_name and base_name in known_metaclass_users:
                # æ¨æ–­ä½¿ç”¨çš„å…ƒç±»
                inferred_metaclass = self._infer_metaclass_from_base(base_name)
                if inferred_metaclass:
                    self._record_metaclass_usage(
                        node.name, inferred_metaclass, node.lineno, 'inheritance_inferred'
                    )
        
        # æ£€æŸ¥ç±»ä½“ä¸­çš„åŠ¨æ€åˆ›å»º
        self._analyze_class_body(node)
        
        self.generic_visit(node)
    
    def visit_Call(self, node: ast.Call):
        """æ£€æŸ¥å‡½æ•°è°ƒç”¨ä¸­çš„åŠ¨æ€åˆ›å»º"""
        func_name = self._get_name(node.func)
        
        # æ£€æŸ¥type()è°ƒç”¨
        if func_name == 'type' and len(node.args) >= 3:
            self._record_dynamic_creation(
                node, 'type_call', 'Dynamic class creation with type()'
            )
        
        # æ£€æŸ¥with_metaclassè°ƒç”¨
        elif func_name == 'with_metaclass' or 'with_metaclass' in func_name:
            self._record_dynamic_creation(
                node, 'metaclass_direct', 'six.with_metaclass usage'
            )
        
        # æ£€æŸ¥å…¶ä»–å·¥å‚æ¨¡å¼
        elif self._is_factory_pattern(node):
            self._record_dynamic_creation(
                node, 'factory_pattern', 'Factory pattern for class creation'
            )
        
        self.generic_visit(node)
    
    def visit_Assign(self, node: ast.Assign):
        """æ£€æŸ¥èµ‹å€¼ä¸­çš„åŠ¨æ€æ“ä½œ"""
        # æ£€æŸ¥__class__èµ‹å€¼
        for target in node.targets:
            if isinstance(target, ast.Attribute) and target.attr == '__class__':
                self._record_dynamic_creation(
                    node, 'class_assignment', '__class__ assignment'
                )
        
        self.generic_visit(node)
    
    def _record_metaclass_usage(self, class_name: str, metaclass_name: str, 
                               line_number: int, usage_type: str):
        """è®°å½•å…ƒç±»ä½¿ç”¨"""
        # è¯„ä¼°å¤æ‚åº¦
        complexity_level = self._assess_metaclass_complexity(metaclass_name)
        
        # ç¡®å®šè¿ç§»ç­–ç•¥
        migration_strategy = self._determine_migration_strategy(metaclass_name)
        
        # è®¾ç½®ä¼˜å…ˆçº§
        priority = self._calculate_migration_priority(metaclass_name, usage_type)
        
        usage = MetaclassUsage(
            class_name=class_name,
            file_path=self.file_path,
            line_number=line_number,
            metaclass_name=metaclass_name,
            usage_type=usage_type,
            complexity_level=complexity_level,
            migration_strategy=migration_strategy,
            migration_priority=priority
        )
        
        self.metaclass_usages.append(usage)
    
    def _record_dynamic_creation(self, node: ast.AST, creation_type: str, 
                                description: str):
        """è®°å½•åŠ¨æ€åˆ›å»º"""
        creation_id = f"{creation_type}_{node.lineno}_{hash(description) % 1000}"
        
        # è·å–åˆ›å»ºä»£ç 
        try:
            code = ast.unparse(node)
        except:
            code = description
        
        # è¯„ä¼°å¤æ‚åº¦
        complexity_score = self._assess_dynamic_complexity(node, creation_type)
        
        # ç¡®å®šè¿ç§»éš¾åº¦
        difficulty = self._assess_migration_difficulty(complexity_score)
        
        creation = DynamicCreation(
            creation_id=creation_id,
            file_path=self.file_path,
            line_number=node.lineno,
            creation_type=creation_type,
            target_class=self._extract_target_class(node),
            creation_code=code,
            complexity_score=complexity_score,
            migration_difficulty=difficulty
        )
        
        self.dynamic_creations.append(creation)
    
    def _analyze_class_body(self, node: ast.ClassDef):
        """åˆ†æç±»ä½“ä¸­çš„ç‰¹æ®Šæ¨¡å¼"""
        for item in node.body:
            # æ£€æŸ¥ç‰¹æ®Šæ–¹æ³•
            if isinstance(item, ast.FunctionDef):
                if item.name in ['__new__', '__init_subclass__', '__metaclass__']:
                    self._record_metaclass_usage(
                        node.name, f'special_method_{item.name}', 
                        item.lineno, 'special_method'
                    )
            
            # æ£€æŸ¥ç±»å˜é‡ä¸­çš„å…ƒç±»å¼•ç”¨
            elif isinstance(item, ast.Assign):
                for target in item.targets:
                    if isinstance(target, ast.Name) and target.id == '__metaclass__':
                        metaclass_name = self._get_name(item.value)
                        if metaclass_name:
                            self._record_metaclass_usage(
                                node.name, metaclass_name, item.lineno, 'class_variable'
                            )
    
    def _assess_metaclass_complexity(self, metaclass_name: str) -> str:
        """è¯„ä¼°å…ƒç±»å¤æ‚åº¦"""
        complex_metaclasses = {
            'MetaLineSeries', 'MetaIndicator', 'MetaStrategy', 'MetaBase'
        }
        medium_metaclasses = {
            'MetaParams', 'MetaBroker', 'MetaObserver', 'MetaAnalyzer'
        }
        
        if metaclass_name in complex_metaclasses:
            return 'complex'
        elif metaclass_name in medium_metaclasses:
            return 'medium'
        else:
            return 'simple'
    
    def _determine_migration_strategy(self, metaclass_name: str) -> str:
        """ç¡®å®šè¿ç§»ç­–ç•¥"""
        strategies = {
            'MetaSingleton': 'Replace with SingletonMixin',
            'MetaParams': 'Replace with ParameterDescriptor',
            'MetaLineSeries': 'Replace with LineDescriptor',
            'MetaIndicator': 'Refactor to composition-based approach',
            'MetaStrategy': 'Use dependency injection pattern',
            'MetaBroker': 'Implement broker registry pattern',
            'MetaBase': 'Remove and simplify class creation'
        }
        
        return strategies.get(metaclass_name, 'Manual refactoring required')
    
    def _calculate_migration_priority(self, metaclass_name: str, usage_type: str) -> int:
        """è®¡ç®—è¿ç§»ä¼˜å…ˆçº§"""
        # åŸºç¡€ä¼˜å…ˆçº§
        base_priority = {
            'MetaSingleton': 2,
            'MetaParams': 1,
            'MetaLineSeries': 1,
            'MetaIndicator': 2,
            'MetaStrategy': 2,
            'MetaBase': 1
        }.get(metaclass_name, 3)
        
        # æ ¹æ®ä½¿ç”¨ç±»å‹è°ƒæ•´
        if usage_type == 'explicit':
            return base_priority
        elif usage_type == 'inheritance':
            return min(base_priority + 1, 5)
        else:
            return min(base_priority + 2, 5)
    
    def _assess_dynamic_complexity(self, node: ast.AST, creation_type: str) -> float:
        """è¯„ä¼°åŠ¨æ€åˆ›å»ºå¤æ‚åº¦"""
        base_score = {
            'type_call': 3.0,
            'metaclass_direct': 4.0,
            'factory_pattern': 2.0,
            'class_assignment': 5.0
        }.get(creation_type, 2.0)
        
        # æ ¹æ®èŠ‚ç‚¹å¤æ‚åº¦è°ƒæ•´
        if hasattr(node, 'args') and len(node.args) > 3:
            base_score += 1.0
        
        if hasattr(node, 'keywords') and len(node.keywords) > 2:
            base_score += 0.5
        
        return min(base_score, 5.0)
    
    def _assess_migration_difficulty(self, complexity_score: float) -> str:
        """è¯„ä¼°è¿ç§»éš¾åº¦"""
        if complexity_score >= 4.0:
            return 'complex'
        elif complexity_score >= 3.0:
            return 'hard'
        elif complexity_score >= 2.0:
            return 'medium'
        else:
            return 'easy'
    
    def _is_factory_pattern(self, node: ast.Call) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å‚æ¨¡å¼"""
        func_name = self._get_name(node.func)
        if not func_name:
            return False
        
        factory_patterns = [
            'create_class', 'make_class', 'build_class',
            'class_factory', 'type_factory'
        ]
        
        return any(pattern in func_name.lower() for pattern in factory_patterns)
    
    def _extract_target_class(self, node: ast.AST) -> str:
        """æå–ç›®æ ‡ç±»å"""
        if isinstance(node, ast.Call):
            if hasattr(node, 'args') and node.args:
                first_arg = node.args[0]
                if isinstance(first_arg, ast.Constant):
                    return str(first_arg.value)
                elif isinstance(first_arg, ast.Name):
                    return first_arg.id
        
        return 'unknown'
    
    def _get_name(self, node):
        """è·å–èŠ‚ç‚¹åç§°"""
        if isinstance(node, ast.Name):
            return node.id
        elif isinstance(node, ast.Attribute):
            value = self._get_name(node.value)
            return f"{value}.{node.attr}" if value else node.attr
        elif isinstance(node, ast.Constant):
            return str(node.value)
        return None
    
    def _infer_metaclass_from_base(self, base_name: str) -> Optional[str]:
        """ä»åŸºç±»æ¨æ–­å…ƒç±»"""
        metaclass_mapping = {
            'ParamsBase': 'MetaParams',
            'LineSeries': 'MetaLineSeries', 
            'LineMultiple': 'MetaLineSeries',
            'Strategy': 'MetaStrategy',
            'Indicator': 'MetaIndicator',
            'Observer': 'MetaObserver',
            'Analyzer': 'MetaAnalyzer',
            'Store': 'MetaSingleton',
            'BrokerBase': 'MetaBroker',
            'DataBase': 'MetaAbstractDataBase',
            'Timer': 'MetaParams',
            'Sizer': 'MetaParams',
            'Filter': 'MetaParams',
            'LineIterator': 'MetaLineIterator'
        }
        return metaclass_mapping.get(base_name)


class MetaclassDetectionTool:
    """å…ƒç¼–ç¨‹æ£€æµ‹å·¥å…·ä¸»ç±»"""
    
    def __init__(self, project_root: str = '.'):
        self.project_root = os.path.abspath(project_root)
        self.all_metaclass_usages: List[MetaclassUsage] = []
        self.all_dynamic_creations: List[DynamicCreation] = []
        self.migration_plans: List[MigrationPlan] = []
        self.file_analysis: Dict[str, Dict] = {}
    
    def detect_metaclass_usage(self):
        """æ£€æµ‹é¡¹ç›®ä¸­çš„å…ƒç±»ä½¿ç”¨"""
        print("å¼€å§‹æ£€æµ‹å…ƒç±»ä½¿ç”¨...")
        
        for root, dirs, files in os.walk(self.project_root):
            # è·³è¿‡ä¸€äº›ç›®å½•
            dirs[:] = [d for d in dirs if not d.startswith('.') and 
                      d not in ['__pycache__', 'build', 'dist', 'tests']]
            
            for file in files:
                if file.endswith('.py'):
                    file_path = os.path.join(root, file)
                    rel_path = os.path.relpath(file_path, self.project_root)
                    
                    # åªåˆ†æbacktraderåŒ…å†…çš„æ–‡ä»¶
                    if rel_path.startswith('backtrader' + os.sep) or file in ['__init__.py']:
                        try:
                            self.analyze_file(file_path, rel_path)
                        except Exception as e:
                            print(f"åˆ†ææ–‡ä»¶ {rel_path} æ—¶å‡ºé”™: {e}")
    
    def analyze_file(self, file_path: str, rel_path: str):
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # å…ˆç”¨æ­£åˆ™è¡¨è¾¾å¼å¿«é€Ÿæ‰«æå…ƒç±»ä½¿ç”¨
            self._regex_scan_metaclass_usage(content, rel_path)
            
            # ASTåˆ†æ
            tree = ast.parse(content)
            detector = MetaclassDetector(rel_path)
            detector.visit(tree)
            
            # æ”¶é›†ç»“æœ
            self.all_metaclass_usages.extend(detector.metaclass_usages)
            self.all_dynamic_creations.extend(detector.dynamic_creations)
            
            # æ–‡ä»¶çº§ç»Ÿè®¡
            self.file_analysis[rel_path] = {
                'metaclass_count': len(detector.metaclass_usages),
                'dynamic_creation_count': len(detector.dynamic_creations),
                'complexity_score': self._calculate_file_complexity(detector)
            }
            
        except Exception as e:
            print(f"æ— æ³•è§£ææ–‡ä»¶ {rel_path}: {e}")
    
    def _regex_scan_metaclass_usage(self, content: str, file_path: str):
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ‰«æå…ƒç±»ä½¿ç”¨"""
        lines = content.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            line = line.strip()
            
            # æ£€æŸ¥metaclass=è¯­æ³•
            metaclass_match = re.search(r'metaclass\s*=\s*(\w+)', line)
            if metaclass_match:
                metaclass_name = metaclass_match.group(1)
                if metaclass_name in {
                    'MetaBase', 'MetaParams', 'MetaLineSeries', 'MetaSingleton',
                    'MetaIndicator', 'MetaStrategy', 'MetaAnalyzer', 'MetaObserver',
                    'MetaBroker', 'MetaLineRoot', 'MetaLineIterator', 'MetaLineActions',
                    'MetaAbstractDataBase', 'MetaCSVDataBase', 'MetaFilter',
                    'MetaMovAvBase', 'MetaDataTrades', 'MetaTimeFrameAnalyzerBase',
                    'MetaSigStrategy', 'MetaIBBroker', 'MetaCTPBroker', 'MetaVCBroker',
                    'MetaOandaBroker', 'MetaCCXTBroker', 'MetaCryptoBroker',
                    'MetaCCXTFeed', 'MetaCryptoFeed', 'MetaCTPData', 'MetaOandaData',
                    'MetaRollOver', 'MetaIBData', 'MetaVCData', 'MetaVChartFile',
                    'MetaChainer'
                }:
                    # æå–ç±»å
                    class_match = re.search(r'class\s+(\w+)', line)
                    class_name = class_match.group(1) if class_match else 'unknown'
                    
                    usage = MetaclassUsage(
                        class_name=class_name,
                        file_path=file_path,
                        line_number=line_num,
                        metaclass_name=metaclass_name,
                        usage_type='explicit_regex',
                        complexity_level=self._assess_metaclass_complexity_quick(metaclass_name),
                        migration_strategy=self._determine_migration_strategy_quick(metaclass_name),
                        migration_priority=self._calculate_migration_priority_quick(metaclass_name)
                    )
                    
                    self.all_metaclass_usages.append(usage)
            
            # æ£€æŸ¥classå®šä¹‰ä¸­çš„ç»§æ‰¿
            class_inherit_match = re.search(r'class\s+(\w+)\s*\([^)]*(\w*Meta\w*)[^)]*\)', line)
            if class_inherit_match:
                class_name = class_inherit_match.group(1)
                inherited_name = class_inherit_match.group(2)
                
                if 'Meta' in inherited_name:
                    usage = MetaclassUsage(
                        class_name=class_name,
                        file_path=file_path,
                        line_number=line_num,
                        metaclass_name=inherited_name,
                        usage_type='inheritance_regex',
                        complexity_level=self._assess_metaclass_complexity_quick(inherited_name),
                        migration_strategy=self._determine_migration_strategy_quick(inherited_name),
                        migration_priority=self._calculate_migration_priority_quick(inherited_name)
                    )
                    
                    self.all_metaclass_usages.append(usage)
    
    def _assess_metaclass_complexity_quick(self, metaclass_name: str) -> str:
        """å¿«é€Ÿè¯„ä¼°å…ƒç±»å¤æ‚åº¦"""
        complex_metaclasses = {'MetaLineSeries', 'MetaIndicator', 'MetaStrategy', 'MetaBase'}
        medium_metaclasses = {'MetaParams', 'MetaBroker', 'MetaObserver', 'MetaAnalyzer'}
        
        if metaclass_name in complex_metaclasses:
            return 'complex'
        elif metaclass_name in medium_metaclasses:
            return 'medium'
        else:
            return 'simple'
    
    def _determine_migration_strategy_quick(self, metaclass_name: str) -> str:
        """å¿«é€Ÿç¡®å®šè¿ç§»ç­–ç•¥"""
        strategies = {
            'MetaSingleton': 'Replace with SingletonMixin',
            'MetaParams': 'Replace with ParameterDescriptor',
            'MetaLineSeries': 'Replace with LineDescriptor',
            'MetaIndicator': 'Refactor to composition-based approach',
            'MetaStrategy': 'Use dependency injection pattern',
            'MetaBroker': 'Implement broker registry pattern',
            'MetaBase': 'Remove and simplify class creation'
        }
        return strategies.get(metaclass_name, 'Manual refactoring required')
    
    def _calculate_migration_priority_quick(self, metaclass_name: str) -> int:
        """å¿«é€Ÿè®¡ç®—è¿ç§»ä¼˜å…ˆçº§"""
        priority_map = {
            'MetaSingleton': 2,
            'MetaParams': 1, 
            'MetaLineSeries': 1,
            'MetaIndicator': 2,
            'MetaStrategy': 2,
            'MetaBase': 1
        }
        return priority_map.get(metaclass_name, 3)
    
    def analyze_dynamic_creation(self):
        """åˆ†æåŠ¨æ€ç±»åˆ›å»ºæ¨¡å¼"""
        print("åˆ†æåŠ¨æ€ç±»åˆ›å»ºæ¨¡å¼...")
        
        # æŒ‰ç±»å‹åˆ†ç»„åˆ†æ
        creation_types = defaultdict(list)
        for creation in self.all_dynamic_creations:
            creation_types[creation.creation_type].append(creation)
        
        # åˆ†ææ¯ç§ç±»å‹çš„æ¨¡å¼
        for creation_type, creations in creation_types.items():
            print(f"  {creation_type}: {len(creations)} ä¸ªå®ä¾‹")
            
            # å¤æ‚åº¦åˆ†æ
            complexities = [c.complexity_score for c in creations]
            if complexities:
                avg_complexity = sum(complexities) / len(complexities)
                print(f"    å¹³å‡å¤æ‚åº¦: {avg_complexity:.2f}")
    
    def generate_migration_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆè¿ç§»æŠ¥å‘Š"""
        print("ç”Ÿæˆè¿ç§»æŠ¥å‘Š...")
        
        # ç”Ÿæˆè¿ç§»è®¡åˆ’
        self._generate_migration_plans()
        
        # ç»Ÿè®¡ä¿¡æ¯
        report = {
            'analysis_time': datetime.now().isoformat(),
            'summary': {
                'total_files_analyzed': len(self.file_analysis),
                'total_metaclass_usages': len(self.all_metaclass_usages),
                'total_dynamic_creations': len(self.all_dynamic_creations),
                'total_migration_plans': len(self.migration_plans),
                'high_priority_migrations': len([u for u in self.all_metaclass_usages if u.migration_priority <= 2]),
                'complex_migrations': len([u for u in self.all_metaclass_usages if u.complexity_level == 'complex'])
            },
            'metaclass_breakdown': self._get_metaclass_breakdown(),
            'dynamic_creation_breakdown': self._get_dynamic_creation_breakdown(),
            'migration_plans': [
                {
                    'target_class': plan.target_class,
                    'current_pattern': plan.current_pattern,
                    'target_pattern': plan.target_pattern,
                    'estimated_effort': plan.estimated_effort,
                    'migration_steps': plan.migration_steps,
                    'prerequisites': plan.prerequisites,
                    'risk_factors': plan.risk_factors
                }
                for plan in self.migration_plans
            ],
            'priority_matrix': self._generate_priority_matrix(),
            'file_analysis': self.file_analysis,
            'recommendations': self._generate_recommendations()
        }
        
        return report
    
    def _generate_migration_plans(self):
        """ç”Ÿæˆè¿ç§»è®¡åˆ’"""
        # æŒ‰å…ƒç±»åˆ†ç»„
        metaclass_groups = defaultdict(list)
        for usage in self.all_metaclass_usages:
            metaclass_groups[usage.metaclass_name].append(usage)
        
        # ä¸ºæ¯ä¸ªå…ƒç±»ç”Ÿæˆè¿ç§»è®¡åˆ’
        for metaclass_name, usages in metaclass_groups.items():
            plan = self._create_migration_plan(metaclass_name, usages)
            if plan:
                self.migration_plans.append(plan)
    
    def _create_migration_plan(self, metaclass_name: str, 
                              usages: List[MetaclassUsage]) -> Optional[MigrationPlan]:
        """åˆ›å»ºå•ä¸ªè¿ç§»è®¡åˆ’"""
        if not usages:
            return None
        
        # è®¡ç®—æ€»å·¥ä½œé‡
        base_effort = len(usages) * 2  # æ¯ä¸ªä½¿ç”¨ç‚¹2å°æ—¶åŸºç¡€å·¥ä½œé‡
        complexity_multiplier = {
            'simple': 1.0,
            'medium': 1.5,
            'complex': 2.5
        }
        
        total_effort = 0
        for usage in usages:
            multiplier = complexity_multiplier.get(usage.complexity_level, 1.0)
            total_effort += base_effort * multiplier
        
        # ç”Ÿæˆè¿ç§»æ­¥éª¤
        steps = self._generate_migration_steps(metaclass_name)
        
        # è¯†åˆ«å‰ç½®æ¡ä»¶
        prerequisites = self._identify_prerequisites(metaclass_name)
        
        # è¯†åˆ«é£é™©å› ç´ 
        risk_factors = self._identify_risk_factors(metaclass_name, usages)
        
        plan = MigrationPlan(
            target_class=metaclass_name,
            current_pattern=f"Metaclass-based: {metaclass_name}",
            target_pattern=self._get_target_pattern(metaclass_name),
            migration_steps=steps,
            estimated_effort=int(total_effort),
            prerequisites=prerequisites,
            test_requirements=self._generate_test_requirements(metaclass_name),
            risk_factors=risk_factors
        )
        
        return plan
    
    def _generate_migration_steps(self, metaclass_name: str) -> List[str]:
        """ç”Ÿæˆè¿ç§»æ­¥éª¤"""
        common_steps = [
            "åˆ›å»ºå¤‡ä»½åˆ†æ”¯",
            "ç¼–å†™ç°æœ‰åŠŸèƒ½çš„æµ‹è¯•ç”¨ä¾‹",
            "åˆ†æç°æœ‰å®ç°çš„æ‰€æœ‰åŠŸèƒ½"
        ]
        
        specific_steps = {
            'MetaSingleton': [
                "å®ç°SingletonMixinåŸºç±»",
                "æ›¿æ¢metaclass=MetaSingleton",
                "éªŒè¯å•ä¾‹è¡Œä¸º",
                "æµ‹è¯•çº¿ç¨‹å®‰å…¨æ€§"
            ],
            'MetaParams': [
                "å®ç°ParameterDescriptor",
                "åˆ›å»ºå‚æ•°ç®¡ç†å™¨",
                "æ›¿æ¢å‚æ•°è®¿é—®é€»è¾‘",
                "éªŒè¯å‚æ•°ç»§æ‰¿"
            ],
            'MetaLineSeries': [
                "å®ç°LineDescriptor",
                "åˆ›å»ºLineBufferç³»ç»Ÿ",
                "æ›¿æ¢linesè®¿é—®é€»è¾‘",
                "éªŒè¯æ•°æ®è®¿é—®"
            ]
        }
        
        steps = common_steps + specific_steps.get(metaclass_name, [
            f"åˆ†æ{metaclass_name}çš„å…·ä½“åŠŸèƒ½",
            "è®¾è®¡æ›¿ä»£æ–¹æ¡ˆ",
            "é€æ­¥è¿ç§»",
            "éªŒè¯åŠŸèƒ½å®Œæ•´æ€§"
        ])
        
        steps.extend([
            "è¿è¡Œå›å½’æµ‹è¯•",
            "æ€§èƒ½æµ‹è¯•å¯¹æ¯”",
            "ä»£ç å®¡æŸ¥",
            "æ–‡æ¡£æ›´æ–°"
        ])
        
        return steps
    
    def _identify_prerequisites(self, metaclass_name: str) -> List[str]:
        """è¯†åˆ«å‰ç½®æ¡ä»¶"""
        prerequisites = {
            'MetaSingleton': [
                "SingletonMixinåŸºç±»å®ç°å®Œæˆ"
            ],
            'MetaParams': [
                "ParameterDescriptorç³»ç»Ÿå®Œæˆ",
                "å‚æ•°ç»§æ‰¿æœºåˆ¶æµ‹è¯•é€šè¿‡"
            ],
            'MetaLineSeries': [
                "LineDescriptorç³»ç»Ÿå®Œæˆ",
                "LineBufferæ€§èƒ½éªŒè¯é€šè¿‡"
            ]
        }
        
        return prerequisites.get(metaclass_name, [])
    
    def _identify_risk_factors(self, metaclass_name: str, 
                              usages: List[MetaclassUsage]) -> List[str]:
        """è¯†åˆ«é£é™©å› ç´ """
        risk_factors = []
        
        # åŸºäºä½¿ç”¨æ•°é‡çš„é£é™©
        if len(usages) > 10:
            risk_factors.append(f"å¤§é‡ä½¿ç”¨ç‚¹({len(usages)}ä¸ª)ï¼Œå½±å“é¢å¹¿")
        
        # åŸºäºå¤æ‚åº¦çš„é£é™©
        complex_usages = [u for u in usages if u.complexity_level == 'complex']
        if complex_usages:
            risk_factors.append(f"åŒ…å«{len(complex_usages)}ä¸ªå¤æ‚ä½¿ç”¨ç‚¹")
        
        # ç‰¹å®šå…ƒç±»çš„é£é™©
        specific_risks = {
            'MetaLineSeries': [
                "æ€§èƒ½æ•æ„Ÿï¼Œéœ€è¦ä»”ç»†éªŒè¯",
                "æ¶‰åŠæ ¸å¿ƒæ•°æ®è®¿é—®é€»è¾‘"
            ],
            'MetaIndicator': [
                "å½±å“æ‰€æœ‰æŒ‡æ ‡è®¡ç®—",
                "å¯èƒ½å½±å“ç¬¬ä¸‰æ–¹æ‰©å±•"
            ],
            'MetaStrategy': [
                "å½±å“ç­–ç•¥æ‰§è¡Œæµç¨‹",
                "å‘åå…¼å®¹æ€§è¦æ±‚é«˜"
            ]
        }
        
        risk_factors.extend(specific_risks.get(metaclass_name, []))
        
        return risk_factors
    
    def _generate_test_requirements(self, metaclass_name: str) -> List[str]:
        """ç”Ÿæˆæµ‹è¯•è¦æ±‚"""
        base_requirements = [
            "åŠŸèƒ½å®Œæ•´æ€§æµ‹è¯•",
            "æ€§èƒ½å›å½’æµ‹è¯•",
            "å†…å­˜æ³„æ¼æ£€æŸ¥"
        ]
        
        specific_requirements = {
            'MetaSingleton': [
                "å•ä¾‹æ¨¡å¼æµ‹è¯•",
                "çº¿ç¨‹å®‰å…¨æµ‹è¯•",
                "å¤šè¿›ç¨‹ç¯å¢ƒæµ‹è¯•"
            ],
            'MetaParams': [
                "å‚æ•°ç»§æ‰¿æµ‹è¯•",
                "å‚æ•°éªŒè¯æµ‹è¯•",
                "é»˜è®¤å€¼å¤„ç†æµ‹è¯•"
            ],
            'MetaLineSeries': [
                "æ•°æ®è®¿é—®æµ‹è¯•",
                "ç´¢å¼•æ“ä½œæµ‹è¯•",
                "å¤§æ•°æ®é›†æ€§èƒ½æµ‹è¯•"
            ]
        }
        
        return base_requirements + specific_requirements.get(metaclass_name, [])
    
    def _get_target_pattern(self, metaclass_name: str) -> str:
        """è·å–ç›®æ ‡æ¨¡å¼"""
        patterns = {
            'MetaSingleton': 'SingletonMixin + normal inheritance',
            'MetaParams': 'ParameterDescriptor + configuration system',
            'MetaLineSeries': 'LineDescriptor + buffer management',
            'MetaIndicator': 'Composition-based indicator system',
            'MetaStrategy': 'Dependency injection pattern'
        }
        
        return patterns.get(metaclass_name, 'Standard class inheritance')
    
    def _calculate_file_complexity(self, detector: MetaclassDetector) -> float:
        """è®¡ç®—æ–‡ä»¶å¤æ‚åº¦"""
        score = 0.0
        
        # å…ƒç±»ä½¿ç”¨å¤æ‚åº¦
        for usage in detector.metaclass_usages:
            complexity_scores = {'simple': 1.0, 'medium': 2.0, 'complex': 3.0}
            score += complexity_scores.get(usage.complexity_level, 1.0)
        
        # åŠ¨æ€åˆ›å»ºå¤æ‚åº¦
        for creation in detector.dynamic_creations:
            score += creation.complexity_score
        
        return score
    
    def _get_metaclass_breakdown(self) -> Dict[str, int]:
        """è·å–å…ƒç±»ä½¿ç”¨ç»Ÿè®¡"""
        breakdown = defaultdict(int)
        for usage in self.all_metaclass_usages:
            breakdown[usage.metaclass_name] += 1
        return dict(breakdown)
    
    def _get_dynamic_creation_breakdown(self) -> Dict[str, int]:
        """è·å–åŠ¨æ€åˆ›å»ºç»Ÿè®¡"""
        breakdown = defaultdict(int)
        for creation in self.all_dynamic_creations:
            breakdown[creation.creation_type] += 1
        return dict(breakdown)
    
    def _generate_priority_matrix(self) -> Dict[str, Dict[str, Any]]:
        """ç”Ÿæˆä¼˜å…ˆçº§çŸ©é˜µ"""
        matrix = {}
        
        for usage in self.all_metaclass_usages:
            key = f"{usage.metaclass_name}_{usage.class_name}"
            matrix[key] = {
                'metaclass_name': usage.metaclass_name,
                'class_name': usage.class_name,
                'file_path': usage.file_path,
                'priority': usage.migration_priority,
                'complexity': usage.complexity_level,
                'migration_strategy': usage.migration_strategy,
                'usage_type': usage.usage_type
            }
        
        return matrix
    
    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        # åŸºäºç»Ÿè®¡çš„å»ºè®®
        if len(self.all_metaclass_usages) > 50:
            recommendations.append("å…ƒç±»ä½¿ç”¨è¾ƒå¤šï¼Œå»ºè®®åˆ†é˜¶æ®µè¿›è¡Œè¿ç§»")
        
        high_priority = [u for u in self.all_metaclass_usages if u.migration_priority <= 2]
        if high_priority:
            recommendations.append(f"ä¼˜å…ˆå¤„ç†{len(high_priority)}ä¸ªé«˜ä¼˜å…ˆçº§è¿ç§»é¡¹")
        
        complex_items = [u for u in self.all_metaclass_usages if u.complexity_level == 'complex']
        if complex_items:
            recommendations.append(f"ä»”ç»†è§„åˆ’{len(complex_items)}ä¸ªå¤æ‚è¿ç§»é¡¹")
        
        # åŸºäºåŠ¨æ€åˆ›å»ºçš„å»ºè®®
        if self.all_dynamic_creations:
            recommendations.append("å‘ç°åŠ¨æ€ç±»åˆ›å»ºï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†")
        
        # é»˜è®¤å»ºè®®
        if not recommendations:
            recommendations = [
                "å»ºç«‹è¯¦ç»†çš„æµ‹è¯•è¦†ç›–",
                "åˆ¶å®šå›æ»šè®¡åˆ’",
                "åˆ†é˜¶æ®µéªŒè¯è¿ç§»ç»“æœ"
            ]
        
        return recommendations
    
    def save_report(self, report: Dict[str, Any]) -> str:
        """ä¿å­˜æ£€æµ‹æŠ¥å‘Š"""
        os.makedirs('analysis_results', exist_ok=True)
        filename = f"analysis_results/metaclass_detection_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"å…ƒç¼–ç¨‹æ£€æµ‹æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
        return filename
    
    def print_summary(self, report: Dict[str, Any]):
        """æ‰“å°æ£€æµ‹æ‘˜è¦"""
        print("="*70)
        print("Backtrader å…ƒç¼–ç¨‹æ£€æµ‹æŠ¥å‘Š")
        print("="*70)
        
        summary = report['summary']
        print(f"åˆ†ææ–‡ä»¶æ•°: {summary['total_files_analyzed']}")
        print(f"å…ƒç±»ä½¿ç”¨ç‚¹: {summary['total_metaclass_usages']}")
        print(f"åŠ¨æ€åˆ›å»ºç‚¹: {summary['total_dynamic_creations']}")
        print(f"è¿ç§»è®¡åˆ’æ•°: {summary['total_migration_plans']}")
        print(f"é«˜ä¼˜å…ˆçº§è¿ç§»: {summary['high_priority_migrations']}")
        print(f"å¤æ‚è¿ç§»é¡¹: {summary['complex_migrations']}")
        
        print("\nğŸ¯ å…ƒç±»ä½¿ç”¨ç»Ÿè®¡:")
        print("-"*40)
        for metaclass, count in report['metaclass_breakdown'].items():
            print(f"{metaclass:<20} {count:>3} æ¬¡")
        
        print("\nğŸ”§ åŠ¨æ€åˆ›å»ºç»Ÿè®¡:")
        print("-"*40)
        for creation_type, count in report['dynamic_creation_breakdown'].items():
            print(f"{creation_type:<20} {count:>3} æ¬¡")
        
        print("\nğŸ“‹ ä¸»è¦è¿ç§»è®¡åˆ’:")
        print("-"*50)
        print(f"{'ç›®æ ‡ç±»':<20} {'é¢„ä¼°å·¥æ—¶':<10} {'å‰ç½®æ¡ä»¶æ•°':<10}")
        print("-"*50)
        for plan in report['migration_plans'][:10]:
            print(f"{plan['target_class']:<20} {plan['estimated_effort']:<10} {len(plan['prerequisites']):<10}")
        
        print("\nğŸ’¡ å»ºè®®:")
        print("-"*30)
        for rec in report['recommendations']:
            print(f"â€¢ {rec}")


def main():
    """ä¸»å‡½æ•°"""
    try:
        print("Day 8-10: å¼€å§‹å…ƒç¼–ç¨‹æ£€æµ‹å·¥å…·åˆ†æ...")
        
        tool = MetaclassDetectionTool()
        
        # æ£€æµ‹å…ƒç±»ä½¿ç”¨
        tool.detect_metaclass_usage()
        
        # åˆ†æåŠ¨æ€åˆ›å»º
        tool.analyze_dynamic_creation()
        
        # ç”Ÿæˆè¿ç§»æŠ¥å‘Š
        report = tool.generate_migration_report()
        
        tool.print_summary(report)
        tool.save_report(report)
        
        print("\nDay 8-10ä»»åŠ¡å®Œæˆï¼")
        
    except Exception as e:
        print(f"å…ƒç¼–ç¨‹æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main() 
#!/usr/bin/env python3
"""
Backtrader Critical Path Analyzer

è¯†åˆ«é‡æ„è¿‡ç¨‹ä¸­çš„å…³é”®è·¯å¾„å’Œé£é™©ç‚¹ï¼Œåˆ†æä¾èµ–é“¾å’Œç“¶é¢ˆã€‚
"""

import json
import os
import sys
from collections import defaultdict, deque
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Dict, List, Set, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


@dataclass
class CriticalPath:
    """å…³é”®è·¯å¾„"""

    path_id: str
    classes: List[str]
    total_complexity: float
    estimated_duration: int
    bottlenecks: List[str]
    risk_level: str
    impact_scope: str


@dataclass
class Bottleneck:
    """ç“¶é¢ˆç‚¹"""

    class_name: str
    bottleneck_type: str  # 'dependency', 'complexity', 'risk'
    severity: str  # 'low', 'medium', 'high', 'critical'
    affected_classes: List[str]
    suggested_resolution: str


class CriticalPathAnalyzer:
    """å…³é”®è·¯å¾„åˆ†æå™¨"""

    def __init__(self):
        self.dependency_data: Dict[str, Any] = {}
        self.implementation_plan: Dict[str, Any] = {}
        self.critical_paths: List[CriticalPath] = []
        self.bottlenecks: List[Bottleneck] = []

        # é¢„å®šä¹‰çš„æ ¸å¿ƒç±»ï¼ˆæ¡†æ¶å…³é”®èŠ‚ç‚¹ï¼‰
        self.core_classes = {
            "Cerebro",
            "Strategy",
            "Indicator",
            "LineSeriesBase",
            "DataBase",
            "BrokerBase",
            "FeedBase",
            "MetaParams",
            "MetaLineSeries",
            "MetaSingleton",
            "MetaBase",
            "LineIterator",
        }

    def load_analysis_data(self):
        """åŠ è½½åˆ†ææ•°æ®"""
        # åŠ è½½ä¾èµ–åˆ†ææ•°æ®
        try:
            dep_files = [
                f for f in os.listdir("analysis_results") if f.startswith("dependency_analysis_")
            ]
            if dep_files:
                latest_dep = sorted(dep_files)[-1]
                with open(f"analysis_results/{latest_dep}", encoding="utf-8") as f:
                    self.dependency_data = json.load(f)
                print(f"å·²åŠ è½½ä¾èµ–åˆ†ææ•°æ®: {latest_dep}")
        except Exception as e:
            print(f"æ— æ³•åŠ è½½ä¾èµ–åˆ†ææ•°æ®: {e}")

        # åŠ è½½å®æ–½è®¡åˆ’æ•°æ®
        try:
            plan_files = [
                f for f in os.listdir("planning_results") if f.startswith("implementation_plan_")
            ]
            if plan_files:
                latest_plan = sorted(plan_files)[-1]
                with open(f"planning_results/{latest_plan}", encoding="utf-8") as f:
                    self.implementation_plan = json.load(f)
                print(f"å·²åŠ è½½å®æ–½è®¡åˆ’æ•°æ®: {latest_plan}")
        except Exception as e:
            print(f"æ— æ³•åŠ è½½å®æ–½è®¡åˆ’æ•°æ®: {e}")

    def analyze_critical_paths(self):
        """åˆ†æå…³é”®è·¯å¾„"""
        if not self.dependency_data:
            print("ç¼ºå°‘ä¾èµ–æ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿåˆ†æ")
            self._create_mock_analysis()
            return

        # ä»ä¾èµ–æ•°æ®ä¸­åˆ†æè·¯å¾„
        priority_matrix = self.dependency_data.get("priority_matrix", {})
        risk_assessments = self.dependency_data.get("risk_assessments", [])

        # 1. åŸºäºä¾èµ–å…³ç³»çš„è·¯å¾„
        dependency_paths = self._analyze_dependency_paths(priority_matrix)

        # 2. åŸºäºé£é™©è¯„ä¼°çš„è·¯å¾„
        risk_paths = self._analyze_risk_paths(risk_assessments)

        # 3. åŸºäºå¤æ‚åº¦çš„è·¯å¾„
        complexity_paths = self._analyze_complexity_paths(priority_matrix)

        self.critical_paths = dependency_paths + risk_paths + complexity_paths

        # å»é‡å’Œæ’åº
        self._deduplicate_and_sort_paths()

        print(f"åˆ†æå‡º {len(self.critical_paths)} æ¡å…³é”®è·¯å¾„")

    def _analyze_dependency_paths(self, priority_matrix: Dict) -> List[CriticalPath]:
        """åˆ†æä¾èµ–è·¯å¾„"""
        paths = []

        # æ„å»ºä¾èµ–å›¾
        dependencies = defaultdict(list)
        for class_name, info in priority_matrix.items():
            for prerequisite in info.get("prerequisites", []):
                if "é‡æ„åŸºç±»:" in prerequisite:
                    base_class = prerequisite.split(":")[1].strip()
                    dependencies[base_class].append(class_name)

        # æ‰¾åˆ°ä¾èµ–é“¾
        for root_class, dependent_classes in dependencies.items():
            if len(dependent_classes) >= 2:  # è‡³å°‘2ä¸ªä¾èµ–ç±»
                chain = [root_class] + dependent_classes
                path = self._create_path_from_chain(chain, "dependency")
                paths.append(path)

        return paths

    def _analyze_risk_paths(self, risk_assessments: List) -> List[CriticalPath]:
        """åˆ†æé£é™©è·¯å¾„"""
        paths = []

        # æŒ‰é£é™©çº§åˆ«åˆ†ç»„
        high_risk_classes = []
        for assessment in risk_assessments:
            if assessment["risk_level"] in ["critical", "high"]:
                high_risk_classes.append(assessment["class_name"])

        # åˆ›å»ºé«˜é£é™©è·¯å¾„
        if len(high_risk_classes) >= 3:
            # å°†é«˜é£é™©ç±»åˆ†ç»„ï¼ˆæ¯3ä¸ªä¸€ç»„ï¼‰
            for i in range(0, len(high_risk_classes), 3):
                group = high_risk_classes[i : i + 3]
                if len(group) >= 2:
                    path = self._create_path_from_chain(group, "high_risk")
                    paths.append(path)

        return paths

    def _analyze_complexity_paths(self, priority_matrix: Dict) -> List[CriticalPath]:
        """åˆ†æå¤æ‚åº¦è·¯å¾„"""
        paths = []

        # æŒ‰å¤æ‚åº¦æ’åº
        complex_classes = []
        for class_name, info in priority_matrix.items():
            if info.get("complexity_score", 0) >= 4.0:
                complex_classes.append((class_name, info["complexity_score"]))

        complex_classes.sort(key=lambda x: x[1], reverse=True)

        # åˆ›å»ºå¤æ‚åº¦è·¯å¾„ï¼ˆæ¯5ä¸ªé«˜å¤æ‚åº¦ç±»ä¸€ç»„ï¼‰
        for i in range(0, len(complex_classes), 5):
            group = [item[0] for item in complex_classes[i : i + 5]]
            if len(group) >= 3:
                path = self._create_path_from_chain(group, "complexity")
                paths.append(path)

        return paths

    def _create_path_from_chain(self, chain: List[str], path_type: str) -> CriticalPath:
        """ä»ç±»é“¾åˆ›å»ºå…³é”®è·¯å¾„"""
        path_id = f"{path_type}_{len(chain)}_{hash(tuple(chain)) % 10000}"

        # ä»ä¾èµ–æ•°æ®è®¡ç®—å¤æ‚åº¦
        total_complexity = 0.0
        if self.dependency_data:
            priority_matrix = self.dependency_data.get("priority_matrix", {})
            for class_name in chain:
                if class_name in priority_matrix:
                    total_complexity += priority_matrix[class_name].get("complexity_score", 1.0)
        else:
            total_complexity = len(chain) * 2.0  # é»˜è®¤ä¼°ç®—

        # ä¼°ç®—æŒç»­æ—¶é—´
        estimated_duration = max(len(chain), int(total_complexity))

        # è¯†åˆ«ç“¶é¢ˆ
        bottlenecks = []
        for class_name in chain:
            if class_name in self.core_classes:
                bottlenecks.append(f"{class_name}: æ ¸å¿ƒç±»")

        # ç¡®å®šé£é™©çº§åˆ«
        if path_type == "high_risk":
            risk_level = "high"
        elif total_complexity >= 15.0:
            risk_level = "critical"
        elif total_complexity >= 10.0:
            risk_level = "high"
        elif total_complexity >= 5.0:
            risk_level = "medium"
        else:
            risk_level = "low"

        # è¯„ä¼°å½±å“èŒƒå›´
        if len(chain) >= 5:
            impact_scope = "å…¨é¡¹ç›®å½±å“"
        elif len(chain) >= 3:
            impact_scope = "æ¨¡å—çº§å½±å“"
        else:
            impact_scope = "å±€éƒ¨å½±å“"

        return CriticalPath(
            path_id=path_id,
            classes=chain,
            total_complexity=total_complexity,
            estimated_duration=estimated_duration,
            bottlenecks=bottlenecks,
            risk_level=risk_level,
            impact_scope=impact_scope,
        )

    def _deduplicate_and_sort_paths(self):
        """å»é‡å’Œæ’åºè·¯å¾„"""
        # ç®€å•å»é‡ï¼ˆåŸºäºè·¯å¾„ç±»çš„é›†åˆï¼‰
        seen_class_sets = set()
        unique_paths = []

        for path in self.critical_paths:
            class_set = tuple(sorted(path.classes))
            if class_set not in seen_class_sets:
                seen_class_sets.add(class_set)
                unique_paths.append(path)

        # æŒ‰é£é™©çº§åˆ«å’Œå¤æ‚åº¦æ’åº
        risk_order = {"critical": 0, "high": 1, "medium": 2, "low": 3}
        unique_paths.sort(
            key=lambda p: (risk_order.get(p.risk_level, 3), -p.total_complexity, -len(p.classes))
        )

        self.critical_paths = unique_paths

    def analyze_bottlenecks(self):
        """åˆ†æç“¶é¢ˆ"""
        if not self.dependency_data:
            self._create_mock_bottlenecks()
            return

        priority_matrix = self.dependency_data.get("priority_matrix", {})

        # 1. ä¾èµ–ç“¶é¢ˆ
        for class_name, info in priority_matrix.items():
            dependent_count = info.get("dependent_classes", 0)
            if dependent_count >= 5:
                severity = (
                    "critical"
                    if dependent_count >= 15
                    else "high" if dependent_count >= 10 else "medium"
                )

                bottleneck = Bottleneck(
                    class_name=class_name,
                    bottleneck_type="dependency",
                    severity=severity,
                    affected_classes=[],  # ç®€åŒ–å¤„ç†
                    suggested_resolution=f"ä¼˜å…ˆé‡æ„ {class_name}ï¼Œé‡‡ç”¨æ¸è¿›å¼è¿ç§»",
                )
                self.bottlenecks.append(bottleneck)

        # 2. å¤æ‚åº¦ç“¶é¢ˆ
        for class_name, info in priority_matrix.items():
            complexity = info.get("complexity_score", 0.0)
            if complexity >= 4.0:
                severity = "critical" if complexity >= 6.0 else "high"

                bottleneck = Bottleneck(
                    class_name=class_name,
                    bottleneck_type="complexity",
                    severity=severity,
                    affected_classes=[class_name],
                    suggested_resolution=f"åˆ†è§£ {class_name} çš„å¤æ‚åŠŸèƒ½",
                )
                self.bottlenecks.append(bottleneck)

        # 3. é£é™©ç“¶é¢ˆ
        for class_name, info in priority_matrix.items():
            if info.get("risk_level") in ["critical", "high"] and class_name in self.core_classes:
                bottleneck = Bottleneck(
                    class_name=class_name,
                    bottleneck_type="risk",
                    severity=info.get("risk_level", "medium"),
                    affected_classes=[class_name],
                    suggested_resolution=f"ä¸º {class_name} åˆ¶å®šè¯¦ç»†é‡æ„è®¡åˆ’",
                )
                self.bottlenecks.append(bottleneck)

        # æ’åº
        severity_order = {"critical": 0, "high": 1, "medium": 2, "low": 3}
        self.bottlenecks.sort(key=lambda b: severity_order.get(b.severity, 3))

        print(f"è¯†åˆ«å‡º {len(self.bottlenecks)} ä¸ªç“¶é¢ˆç‚¹")

    def _create_mock_analysis(self):
        """åˆ›å»ºæ¨¡æ‹Ÿåˆ†æï¼ˆå½“ç¼ºå°‘æ•°æ®æ—¶ï¼‰"""
        # æ¨¡æ‹Ÿå…³é”®è·¯å¾„
        mock_paths = [
            CriticalPath(
                path_id="critical_meta_1",
                classes=["MetaParams", "Strategy", "Indicator"],
                total_complexity=12.0,
                estimated_duration=15,
                bottlenecks=["MetaParams: æ ¸å¿ƒç±»"],
                risk_level="critical",
                impact_scope="å…¨é¡¹ç›®å½±å“",
            ),
            CriticalPath(
                path_id="high_lines_1",
                classes=["MetaLineSeries", "LineSeriesBase", "DataBase"],
                total_complexity=10.0,
                estimated_duration=12,
                bottlenecks=["MetaLineSeries: æ ¸å¿ƒç±»"],
                risk_level="high",
                impact_scope="æ¨¡å—çº§å½±å“",
            ),
        ]
        self.critical_paths = mock_paths

    def _create_mock_bottlenecks(self):
        """åˆ›å»ºæ¨¡æ‹Ÿç“¶é¢ˆï¼ˆå½“ç¼ºå°‘æ•°æ®æ—¶ï¼‰"""
        mock_bottlenecks = [
            Bottleneck(
                class_name="MetaParams",
                bottleneck_type="dependency",
                severity="critical",
                affected_classes=["Strategy", "Indicator", "BrokerBase"],
                suggested_resolution="ä¼˜å…ˆé‡æ„MetaParamsï¼Œé‡‡ç”¨å‚æ•°æè¿°ç¬¦æ›¿ä»£",
            ),
            Bottleneck(
                class_name="Cerebro",
                bottleneck_type="complexity",
                severity="high",
                affected_classes=["Cerebro"],
                suggested_resolution="åˆ†è§£Cerebroçš„å¤æ‚åŠŸèƒ½ï¼Œåˆ†é˜¶æ®µé‡æ„",
            ),
        ]
        self.bottlenecks = mock_bottlenecks

    def generate_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report = {
            "analysis_time": datetime.now().isoformat(),
            "summary": {
                "total_critical_paths": len(self.critical_paths),
                "total_bottlenecks": len(self.bottlenecks),
                "critical_risk_paths": len(
                    [p for p in self.critical_paths if p.risk_level == "critical"]
                ),
                "high_risk_paths": len([p for p in self.critical_paths if p.risk_level == "high"]),
                "critical_bottlenecks": len(
                    [b for b in self.bottlenecks if b.severity == "critical"]
                ),
                "high_severity_bottlenecks": len(
                    [b for b in self.bottlenecks if b.severity == "high"]
                ),
            },
            "critical_paths": [
                {
                    "path_id": path.path_id,
                    "classes": path.classes,
                    "total_complexity": path.total_complexity,
                    "estimated_duration": path.estimated_duration,
                    "bottlenecks": path.bottlenecks,
                    "risk_level": path.risk_level,
                    "impact_scope": path.impact_scope,
                }
                for path in self.critical_paths[:15]  # Top 15
            ],
            "bottlenecks": [
                {
                    "class_name": bottleneck.class_name,
                    "bottleneck_type": bottleneck.bottleneck_type,
                    "severity": bottleneck.severity,
                    "affected_classes_count": len(bottleneck.affected_classes),
                    "suggested_resolution": bottleneck.suggested_resolution,
                }
                for bottleneck in self.bottlenecks[:10]  # Top 10
            ],
            "recommendations": self._generate_recommendations(),
        }

        return report

    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆå»ºè®®"""
        recommendations = []

        # åŸºäºå…³é”®è·¯å¾„çš„å»ºè®®
        if len(self.critical_paths) > 5:
            recommendations.append("å…³é”®è·¯å¾„è¾ƒå¤šï¼Œå»ºè®®åˆ¶å®šå¹¶è¡Œæ‰§è¡Œè®¡åˆ’")

        # åŸºäºç“¶é¢ˆçš„å»ºè®®
        critical_bottlenecks = [b for b in self.bottlenecks if b.severity == "critical"]
        if critical_bottlenecks:
            recommendations.append(f"å‘ç° {len(critical_bottlenecks)} ä¸ªå…³é”®ç“¶é¢ˆï¼Œå»ºè®®ä¼˜å…ˆå¤„ç†")

        # åŸºäºé£é™©çš„å»ºè®®
        high_risk_paths = [p for p in self.critical_paths if p.risk_level in ["critical", "high"]]
        if len(high_risk_paths) > 3:
            recommendations.append("é«˜é£é™©è·¯å¾„è¾ƒå¤šï¼Œå»ºè®®å¢åŠ æµ‹è¯•è¦†ç›–")

        # é»˜è®¤å»ºè®®
        if not recommendations:
            recommendations = ["å»ºç«‹å…³é”®è·¯å¾„ç›‘æ§æœºåˆ¶", "åˆ¶å®šç“¶é¢ˆåº”æ€¥é¢„æ¡ˆ", "å®šæœŸè¯„ä¼°é‡æ„è¿›åº¦"]

        return recommendations

    def save_report(self, report: Dict[str, Any]) -> str:
        """ä¿å­˜åˆ†ææŠ¥å‘Š"""
        os.makedirs("analysis_results", exist_ok=True)
        filename = f"analysis_results/critical_path_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        with open(filename, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print(f"å…³é”®è·¯å¾„åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
        return filename

    def print_summary(self, report: Dict[str, Any]):
        """æ‰“å°åˆ†ææ‘˜è¦"""
        print("=" * 70)
        print("Backtrader å…³é”®è·¯å¾„åˆ†ææŠ¥å‘Š")
        print("=" * 70)

        summary = report["summary"]
        print(f"å…³é”®è·¯å¾„æ€»æ•°: {summary['total_critical_paths']}")
        print(f"ç“¶é¢ˆç‚¹æ€»æ•°: {summary['total_bottlenecks']}")
        print(f"å…³é”®é£é™©è·¯å¾„: {summary['critical_risk_paths']}")
        print(f"é«˜é£é™©è·¯å¾„: {summary['high_risk_paths']}")
        print(f"å…³é”®ç“¶é¢ˆ: {summary['critical_bottlenecks']}")
        print(f"é«˜ä¸¥é‡æ€§ç“¶é¢ˆ: {summary['high_severity_bottlenecks']}")

        print("\nğŸ›¤ï¸ æœ€é«˜é£é™©å…³é”®è·¯å¾„ (Top 5):")
        print("-" * 60)
        print(f"{'è·¯å¾„ID':<20} {'ç±»æ•°':<6} {'é£é™©çº§åˆ«':<10} {'é¢„è®¡å¤©æ•°':<8}")
        print("-" * 60)
        for path in report["critical_paths"][:5]:
            print(
                f"{path['path_id']:<20} {len(path['classes']):<6} "
                f"{path['risk_level']:<10} {path['estimated_duration']:<8}"
            )

        print("\nğŸ”’ æœ€ä¸¥é‡ç“¶é¢ˆ (Top 5):")
        print("-" * 60)
        print(f"{'ç±»å':<25} {'ç±»å‹':<12} {'ä¸¥é‡æ€§':<8} {'å½±å“ç±»æ•°':<8}")
        print("-" * 60)
        for bottleneck in report["bottlenecks"][:5]:
            print(
                f"{bottleneck['class_name']:<25} {bottleneck['bottleneck_type']:<12} "
                f"{bottleneck['severity']:<8} {bottleneck['affected_classes_count']:<8}"
            )

        print("\nğŸ’¡ å»ºè®®:")
        print("-" * 30)
        for rec in report["recommendations"]:
            print(f"â€¢ {rec}")


def main():
    """ä¸»å‡½æ•°"""
    try:
        analyzer = CriticalPathAnalyzer()

        print("å¼€å§‹å…³é”®è·¯å¾„åˆ†æ...")
        analyzer.load_analysis_data()
        analyzer.analyze_critical_paths()
        analyzer.analyze_bottlenecks()

        report = analyzer.generate_report()
        analyzer.print_summary(report)
        analyzer.save_report(report)

        print("\nDay 5-7å…³é”®è·¯å¾„åˆ†æå®Œæˆï¼")

    except Exception as e:
        print(f"å…³é”®è·¯å¾„åˆ†ææ—¶å‡ºé”™: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
